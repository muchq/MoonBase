#!/bin/bash

echo "=== Binary Size Comparison ==="
echo ""
echo "This demonstrates the importance of NOT embedding training data in production."
echo ""

# Note: The actual binary sizes will vary, but the pattern is clear:
echo "Approximate sizes:"
echo ""
echo "Training Applications (with embedded MNIST data):"
echo "  mnist_vendored:   ~25-30 MB (includes 11MB MNIST dataset)"
echo "  mnist_real:       ~25-30 MB (includes 11MB MNIST dataset)"
echo ""
echo "Production Application (model only):"
echo "  mnist_production: ~15-20 MB (no dataset, just inference code)"
echo ""
echo "Trained Model Files:"
echo "  model_config.json:   ~1 KB (model architecture)"
echo "  model_weights.json:  ~1-2 MB (trained parameters)"
echo ""
echo "Key Insight:"
echo "- Training apps with data: 25-30 MB binary"
echo "- Production inference:    15-20 MB binary + 1-2 MB model file"
echo "- Savings:                 ~11 MB (the dataset size)"
echo ""
echo "For larger datasets like ImageNet (150GB+), this difference is critical!"